{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9b9243",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b8cd2",
   "metadata": {},
   "source": [
    "### Importing libraries and loading the data into 3 seperate categories: Movies, Ratings, and Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942efe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant modules:\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff5272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data \n",
    "movies = pd.read_table('movies.dat', sep = \"::\", names = ['MovieID','Title', 'Genres'],\n",
    "                       header = None, engine='python')\n",
    "print(movies.head())\n",
    "\n",
    "ratings = pd.read_table('ratings.dat', sep = \"::\", names = ['UserID', 'MovieID', 'Rating', 'Timestamp'],\n",
    "                        header = None, engine='python')\n",
    "print(ratings.head())\n",
    "\n",
    "users = pd.read_table('users.dat', sep = \"::\", names = ['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'],\n",
    "                      header = None, engine='python')\n",
    "\n",
    "ratings_np = ratings.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e974bf7",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a197662",
   "metadata": {},
   "source": [
    "# Naive Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making 5 folds, same 5 folds split used for the 3 first approaches:\n",
    "np.random.seed(120)\n",
    "indices = np.repeat(range(5), (len(ratings)/5)+1)[0:(len(ratings))]\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Setup 2 data frame that will hold the error values. 1 for training set, 1 for testing set\n",
    "accuracy_per_fold_overall = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) # Test set\n",
    "accuracy_per_fold_overall2 = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) # Training set\n",
    "\n",
    "\n",
    "for k in range(5): #Make every fold a test set once\n",
    "    # Split data set into training set and testing set\n",
    "    traindata = ratings.loc[indices != k] \n",
    "    testdata = ratings.loc[indices == k, 'Rating'] \n",
    "    \n",
    "    #Determine mean based on train data of that CV round\n",
    "    mean = traindata[\"Rating\"].mean() # Naive Approach 1 algorithm\n",
    "    \n",
    "    # Convert pandas data frame work to numpy array. Simplifies calculating the RMSE and MAE\n",
    "    testdata_np = testdata.to_numpy()\n",
    "    traindata_np = traindata.to_numpy()\n",
    "    \n",
    "    # Calculate RMSE and MAE for the testing set\n",
    "    rmse = np.sqrt(np.mean(np.square((testdata_np - mean))))\n",
    "    mae = np.mean(np.abs(testdata_np - mean))\n",
    "    \n",
    "    # Calculate RMSE and MAE for the training set\n",
    "    rmse2 = np.sqrt(np.mean(np.square((traindata_np.T[2] - mean))))\n",
    "    mae2 = np.mean(np.abs(traindata_np.T[2] - mean))\n",
    "    \n",
    "    # Add values to testing error data frame\n",
    "    accuracy_per_fold_overall.loc[k,'RMSE'] = rmse #RMSE\n",
    "    accuracy_per_fold_overall.loc[k, 'MAE'] = mae #MAE    \n",
    "    \n",
    "    # Add values to training error data frame\n",
    "    accuracy_per_fold_overall2.loc[k,'RMSE'] = rmse2 #RMSE \n",
    "    accuracy_per_fold_overall2.loc[k, 'MAE'] = mae2 #MAE          \n",
    "\n",
    "print(\"MAE on Testing set:\\t\", accuracy_per_fold_overall.loc[:,'MAE'].mean()) #Average the MAEs\n",
    "print(\"RMSE on Testing set:\\t\", accuracy_per_fold_overall.loc[:,'RMSE'].mean()) #Average the RMSEs\n",
    "print()\n",
    "print(\"MAE on Training set:\\t\", accuracy_per_fold_overall2.loc[:,'MAE'].mean()) #Average the MAEs\n",
    "print(\"RMSE on Training set:\\t\", accuracy_per_fold_overall2.loc[:,'RMSE'].mean()) #Average the RMSEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb96af9",
   "metadata": {},
   "source": [
    "# Naive Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ba575",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    \n",
    "def movie_ratings_mean(np_ratings, item_id):\n",
    "    selected_np = np_ratings[np_ratings[:, 1] == item_id, :]\n",
    "    if len(selected_np) != 0:\n",
    "        return np.mean(selected_np[:,2])\n",
    "    else:  #Exception if there are no ratings in the training set:\n",
    "        #print(item_id,\"No movies available\")\n",
    "        return overall_mean(ratings_np)\n",
    "\n",
    "def overall_mean(ratings_arr): \n",
    "    return ratings_arr[:,2].mean()\n",
    "\n",
    "# Setup 2 data frame that will hold the error values. 1 for training set, 1 for testing set\n",
    "accuracy_per_fold_movie_mean = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) #initializing array\n",
    "accuracy_per_fold_movie_mean2 = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) #initializing array\n",
    "\n",
    "\n",
    "for k in range(5): #Make every fold a test set once\n",
    "    # Split data set into training set and testing set\n",
    "    traindata = ratings.loc[indices != k,:]\n",
    "    testdata = ratings.loc[indices == k,:]\n",
    "    \n",
    "    # Add an additional column where the predicted values will be stored\n",
    "    testdata.loc[:,'Predicted_Rating'] = 999 \n",
    "    traindata.loc[:,'Predicted_Rating'] = 999 \n",
    "    \n",
    "    # Convert pandas data frame work to numpy array. Simplifies calculations\n",
    "    testdata_np = testdata.to_numpy(dtype=\"float64\")\n",
    "    traindata_np = traindata.to_numpy(dtype=\"float64\")\n",
    "    \n",
    "    # Predict movie ratings for each movie in the testing set\n",
    "    for movie in testdata.MovieID.unique(): # Get all the unique movie IDs\n",
    "        a = np.where(testdata_np[:,1] == movie) # Get the location of the movie ID specified by 'movie'\n",
    "        testdata_np[a[0], 4] =  movie_ratings_mean(traindata_np, movie) # Add the average 'movie' rating to \n",
    "                                                                        # the test data matrix\n",
    "    # Predict movie ratings for each movie in the training set\n",
    "    for movie in traindata.MovieID.unique(): # Get all the unique movie IDs\n",
    "        a = np.where(traindata_np[:,1] == movie) # Get the location of the movie ID specified by 'movie'\n",
    "        traindata_np[a[0], 4] =  movie_ratings_mean(traindata_np, movie) # Add the average 'movie' rating to \n",
    "                                                                         # the training data matrix\n",
    "    \n",
    "    # Calculate RMSE and MAE for the testing set\n",
    "    rmse = np.sqrt(np.mean(np.square((testdata_np[:,2] - testdata_np[:,4]))))\n",
    "    mae = np.mean(np.abs(testdata_np[:,2] - testdata_np[:,4]))\n",
    "    \n",
    "    # Add values to testing error data frame\n",
    "    accuracy_per_fold_movie_mean.loc[k, 'RMSE'] = rmse\n",
    "    accuracy_per_fold_movie_mean.loc[k, 'MAE'] = mae\n",
    "    \n",
    "    # Calculate RMSE and MAE for the training set\n",
    "    rmse = np.sqrt(np.mean(np.square((traindata_np[:,2] - traindata_np[:,4]))))\n",
    "    mae = np.mean(np.abs(traindata_np[:,2] - traindata_np[:,4]))\n",
    "    \n",
    "    # Add values to training error data frame\n",
    "    accuracy_per_fold_movie_mean2.loc[k, 'RMSE'] = rmse\n",
    "    accuracy_per_fold_movie_mean2.loc[k, 'MAE'] = mae\n",
    "\n",
    "\n",
    "print(\"MAE on Testing set:\\t\", accuracy_per_fold_movie_mean.loc[:,'MAE'].mean()) #Average the MAEs\n",
    "print(\"RMSE on Testing set:\\t\", accuracy_per_fold_movie_mean.loc[:,'RMSE'].mean()) #Average the RMSEs\n",
    "print()\n",
    "print(\"MAE on Training set:\\t\", accuracy_per_fold_movie_mean2.loc[:,'MAE'].mean()) #Average the MAEs\n",
    "print(\"RMSE on Training set:\\t\", accuracy_per_fold_movie_mean2.loc[:,'RMSE'].mean()) #Average the RMSEs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d5e65",
   "metadata": {},
   "source": [
    "# Naive Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504a00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    \n",
    "def user_ratings_mean(np_ratings, item_id):\n",
    "    selected_np = np_ratings[np_ratings[:, 0] == item_id, :]\n",
    "    if len(selected_np) != 0:\n",
    "        return np.mean(selected_np[:,2])\n",
    "    else:  #Exception if there are no ratings in the training set:\n",
    "        #print(item_id,\"No movies available\")\n",
    "        return overall_mean(ratings_np)\n",
    "    \n",
    "def overall_mean(ratings_arr): \n",
    "    return ratings_arr[:,2].mean()\n",
    "\n",
    "# Setup 2 data frame that will hold the error values. 1 for training set, 1 for testing set\n",
    "accuracy_per_fold_user_mean = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) #initializing array\n",
    "accuracy_per_fold_user_mean2 = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) #initializing array\n",
    "\n",
    "\n",
    "for k in range(5): #Make every fold a test set once\n",
    "    # Split data set into training set and testing set\n",
    "    traindata = ratings.loc[indices != k,:]\n",
    "    testdata = ratings.loc[indices == k,:]\n",
    "    \n",
    "    # Add an additional column where the predicted values will be stored\n",
    "    testdata.loc[:,'Predicted_Rating'] = 999 #Extra column to store the predicted ratings\n",
    "    traindata.loc[:,'Predicted_Rating'] = 999 #Extra column to store the predicted ratings\n",
    "    \n",
    "    # Convert pandas data frame work to numpy array. Simplifies calculations\n",
    "    testdata_np = testdata.to_numpy(dtype=\"float64\")\n",
    "    traindata_np = traindata.to_numpy(dtype=\"float64\")\n",
    "    \n",
    "    # Predict user ratings for each user in the testing set\n",
    "    for user in testdata.UserID.unique(): # Get all the unique user IDs\n",
    "        a = np.where(testdata_np[:,0] == user) # Get the location of the user ID specified by 'user'\n",
    "        testdata_np[a[0], 4] =  user_ratings_mean(traindata_np, user) # Add the average 'user' rating to \n",
    "                                                                      # the test data matrix\n",
    "    # Predict user ratings for each user in the training set\n",
    "    for user in traindata.UserID.unique(): # Get all the unique user IDs\n",
    "        a = np.where(traindata_np[:,0] == user)  # Get the location of the user ID specified by 'user'\n",
    "        traindata_np[a[0], 4] =  user_ratings_mean(traindata_np, user) # Add the average 'user' rating to \n",
    "                                                                       # the training data matrix\n",
    "        \n",
    "    # Calculate RMSE and MAE for the testing set\n",
    "    rmse = np.sqrt(np.mean(np.square((testdata_np[:,2] - testdata_np[:,4]))))\n",
    "    mae = np.mean(np.abs(testdata_np[:,2] - testdata_np[:,4]))\n",
    "    \n",
    "    # Add values to testing error data frame\n",
    "    accuracy_per_fold_user_mean.loc[k, 'RMSE'] = rmse\n",
    "    accuracy_per_fold_user_mean.loc[k, 'MAE'] = mae\n",
    "    \n",
    "    # Calculate RMSE and MAE for the training set\n",
    "    rmse = np.sqrt(np.mean(np.square((traindata_np[:,2] - traindata_np[:,4]))))\n",
    "    mae = np.mean(np.abs(traindata_np[:,2] - traindata_np[:,4]))\n",
    "    \n",
    "    # Add values to training error data frame\n",
    "    accuracy_per_fold_user_mean2.loc[k, 'RMSE'] = rmse\n",
    "    accuracy_per_fold_user_mean2.loc[k, 'MAE'] = mae\n",
    "\n",
    "\n",
    "print(\"MAE on Testing set:\\t\", accuracy_per_fold_user_mean.loc[:,'MAE'].mean()) #Average the MAEs\n",
    "print(\"RMSE on Testing set:\\t\", accuracy_per_fold_user_mean.loc[:,'RMSE'].mean()) #Average the MAEs\n",
    "print()\n",
    "print(\"MAE on Training set:\\t\", accuracy_per_fold_user_mean2.loc[:,'MAE'].mean()) \n",
    "print(\"RMSE on Training set:\\t\", accuracy_per_fold_user_mean2.loc[:,'RMSE'].mean()) #Average the MAEs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762a40a",
   "metadata": {},
   "source": [
    "# Naive Approach 4: Linear regression without intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "#Naive approach 4: Linear regression without intercept\n",
    "def get_ratings_per_movie(train):\n",
    "    ratings_per_movie = pd.DataFrame(train[\"MovieID\"].unique(), columns = ['MovieID'])\n",
    "    ratings_per_movie['Rating'] = [movie_ratings_mean(train, movie) for movie in train.MovieID.unique()]\n",
    "    return ratings_per_movie\n",
    "\n",
    "\n",
    "def get_ratings_per_user(train):\n",
    "    ratings_per_user = pd.DataFrame(train[\"UserID\"].unique(), columns = ['UserID'])\n",
    "    ratings_per_user['Rating'] = [user_ratings_mean(train, user) for user in train.UserID.unique()]\n",
    "    return ratings_per_user\n",
    "\n",
    "def user_ratings_mean(train, user_id):\n",
    "    selected_ratings = train.loc[train.UserID == user_id, 'Rating']\n",
    "    if (len(selected_ratings) != 0):\n",
    "        return selected_ratings.mean()\n",
    "    else: #Exception if there are no ratings in the training set:\n",
    "        return overall_mean(ratings_df)\n",
    "    \n",
    "def movie_ratings_mean(train, item_id):\n",
    "    selected_movies = train.loc[train.MovieID == item_id, 'Rating']\n",
    "    if len(selected_movies) != 0:\n",
    "        return selected_movies.mean()\n",
    "    else:  #Exception if there are no ratings in the training set:\n",
    "        #print(item_id,\"No movies available\")\n",
    "        return overall_mean(train)\n",
    "\n",
    "def get_ratings_extended(user_mean, movie_mean, train):\n",
    "    temp = train.copy()\n",
    "    temp[\"usermean\"] = np.nan\n",
    "    temp[\"itemmean\"] = np.nan\n",
    "    \n",
    "    for user_id in train.UserID.unique():\n",
    "        idx = temp.loc[temp[\"UserID\"] == user_id].index\n",
    "        mean = float(user_mean.loc[user_mean[\"UserID\"] == user_id, \"Rating\"])\n",
    "        temp.loc[idx, 'usermean'] = mean\n",
    "\n",
    "    for movie_id in train.MovieID.unique():\n",
    "        idx = temp.loc[temp[\"MovieID\"] == movie_id].index\n",
    "        mean = float(movie_mean.loc[movie_mean[\"MovieID\"] == movie_id, \"Rating\"])\n",
    "        temp.loc[idx, 'itemmean'] = mean\n",
    "    return temp\n",
    "\n",
    "# Setup 2 data frame that will hold the error values for LR no intercept. 1 for training set, 1 for testing set\n",
    "accuracy_per_fold_reg1 = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) #initializing array\n",
    "accuracy_per_fold_reg2 = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) #initializing array\n",
    "\n",
    "\n",
    "\n",
    "for k in range(5):\n",
    "    # Split data set into training set and testing set\n",
    "    traindata = ratings.loc[indices != k,:]\n",
    "    testdata = ratings.loc[indices == k,:]\n",
    "    \n",
    "    # Get mean ratings for training set\n",
    "    user_mean_ratings = get_ratings_per_user(traindata) # Mean rating per user\n",
    "    movie_mean_ratings = get_ratings_per_movie(traindata) # Mean rating per movie\n",
    "    \n",
    "    # Get mean ratings for testing set\n",
    "    test_user_mean = get_ratings_per_user(testdata) # Mean rating per user\n",
    "    test_movie_mean = get_ratings_per_movie(testdata)  # Mean rating per movie\n",
    "    \n",
    "    # Add mean rating per user & mean rating per movie to the training set\n",
    "    ratings_extended = get_ratings_extended(user_mean_ratings, movie_mean_ratings, traindata)\n",
    "    ratings_extended_t = get_ratings_extended(test_user_mean, test_movie_mean, testdata)\n",
    "\n",
    "    # Add extra columns to the test and training set - Used for adding predictions from both LR models\n",
    "    testdata['Predicted_Rating_reg1'] = 999\n",
    "    \n",
    "    traindata['Predicted_Rating_reg1'] = 999\n",
    "    \n",
    "    # Create a linear regression model with no intercept using mean rating per user and mean rating per movie\n",
    "    regression_1 = LinearRegression(fit_intercept = False).fit(X = ratings_extended[['usermean', 'itemmean']],\n",
    "                                                               y = ratings_extended['Rating'])\n",
    "    \n",
    "   \n",
    "    # Predict ratings using the linear regression model on the testing set\n",
    "    testdata['Predicted_Rating_reg1'] = regression_1.predict(X = ratings_extended_t[['usermean', 'itemmean']])  \n",
    "\n",
    "    # Predict ratings using the linear regression model on the training set    \n",
    "    traindata['Predicted_Rating_reg1'] = regression_1.predict(X = ratings_extended[['usermean', 'itemmean']])  \n",
    "    \n",
    "    # Testing set\n",
    "    # All prediction below 1 is interpreted as 1. Likewise, prediction above 5 is interpreted as 5.\n",
    "    testdata.loc[testdata.Predicted_Rating_reg1 > 5, 'Rating'] = 5 # above 5 with LR no intercept\n",
    "    testdata.loc[testdata.Predicted_Rating_reg1 < 1, 'Rating'] = 1 # below 1 with LR no intercept\n",
    "    \n",
    "    \n",
    "    # Training set\n",
    "    # All prediction below 1 is interpreted as 1. Likewise, prediction above 5 is interpreted as 5.\n",
    "    traindata.loc[traindata.Predicted_Rating_reg1 > 5, 'Rating'] = 5 # above 5 with LR no intercept\n",
    "    traindata.loc[traindata.Predicted_Rating_reg1 < 1, 'Rating'] = 1 # below 1 with LR no intercept\n",
    "\n",
    "    \n",
    "    # Calculate RMSE and MAE for the testing set on LR model without intercept\n",
    "    rmse = (testdata.Rating - testdata.Predicted_Rating_reg1)**2\n",
    "    mae = abs(testdata.Rating- testdata.Predicted_Rating_reg1)\n",
    "    \n",
    "    # Add values to testing error data frame for LR model without intercept\n",
    "    accuracy_per_fold_reg1.loc[k, 'RMSE'] = np.sqrt(np.mean(rmse))\n",
    "    accuracy_per_fold_reg1.loc[k, 'MAE'] = (sum(mae)/len(mae))\n",
    "    \n",
    "    \n",
    "    # Calculate RMSE and MAE for the training set on LR model without intercept\n",
    "    rmse = (traindata.Rating - traindata.Predicted_Rating_reg1)**2\n",
    "    mae = abs(traindata.Rating- traindata.Predicted_Rating_reg1)\n",
    "    \n",
    "    # Add values to training set error data frame for LR model with intercept\n",
    "    accuracy_per_fold_reg1_2.loc[k, 'RMSE'] = np.sqrt(np.mean(rmse))\n",
    "    accuracy_per_fold_reg1_2.loc[k, 'MAE'] = (sum(mae)/len(mae))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Testing Set\")\n",
    "print(\"MAE on Testing set for Regression 1:\\t\", accuracy_per_fold_reg1.loc[:,'MAE'].mean()) #Average the MAEs\n",
    "print(\"RMSE on Testing set for Regression 1:\\t\", accuracy_per_fold_reg1.loc[:,'RMSE'].mean()) \n",
    "\n",
    "print(\"Training set\")\n",
    "print(\"MAE on Training set for Regression 1:\\t\", accuracy_per_fold_reg1_2.loc[:,'MAE'].mean()) #Average the MAEs\n",
    "print(\"RMSE on Training set for Regression 1:\\t\", accuracy_per_fold_reg1_2.loc[:,'RMSE'].mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3279dd",
   "metadata": {},
   "source": [
    "# Naive Approach 5: with intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_per_movie(train):\n",
    "    ratings_per_movie = pd.DataFrame(train[\"MovieID\"].unique(), columns = ['MovieID'])\n",
    "    ratings_per_movie['Rating'] = [movie_ratings_mean(train, movie) for movie in train.MovieID.unique()]\n",
    "    return ratings_per_movie\n",
    "\n",
    "\n",
    "def get_ratings_per_user(train):\n",
    "    ratings_per_user = pd.DataFrame(train[\"UserID\"].unique(), columns = ['UserID'])\n",
    "    ratings_per_user['Rating'] = [user_ratings_mean(train, user) for user in train.UserID.unique()]\n",
    "    return ratings_per_user\n",
    "\n",
    "def user_ratings_mean(train, user_id):\n",
    "    selected_ratings = train.loc[train.UserID == user_id, 'Rating']\n",
    "    if (len(selected_ratings) != 0):\n",
    "        return selected_ratings.mean()\n",
    "    else: #Exception if there are no ratings in the training set:\n",
    "        return overall_mean(ratings_df)\n",
    "    \n",
    "def movie_ratings_mean(train, item_id):\n",
    "    selected_movies = train.loc[train.MovieID == item_id, 'Rating']\n",
    "    if len(selected_movies) != 0:\n",
    "        return selected_movies.mean()\n",
    "    else:  #Exception if there are no ratings in the training set:\n",
    "        #print(item_id,\"No movies available\")\n",
    "        return overall_mean(train)\n",
    "\n",
    "def get_ratings_extended(user_mean, movie_mean, train):\n",
    "    temp = train.copy()\n",
    "    temp[\"usermean\"] = np.nan\n",
    "    temp[\"itemmean\"] = np.nan\n",
    "    \n",
    "    for user_id in train.UserID.unique():\n",
    "        idx = temp.loc[temp[\"UserID\"] == user_id].index\n",
    "        mean = float(user_mean.loc[user_mean[\"UserID\"] == user_id, \"Rating\"])\n",
    "        temp.loc[idx, 'usermean'] = mean\n",
    "\n",
    "    for movie_id in train.MovieID.unique():\n",
    "        idx = temp.loc[temp[\"MovieID\"] == movie_id].index\n",
    "        mean = float(movie_mean.loc[movie_mean[\"MovieID\"] == movie_id, \"Rating\"])\n",
    "        temp.loc[idx, 'itemmean'] = mean\n",
    "    return temp\n",
    "    \n",
    "# Setup 2 data frame that will hold the error values for LR with intercept. 1 for training set, 1 for testing set\n",
    "accuracy_per_fold_reg1 = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) # Training set\n",
    "accuracy_per_fold_reg2 = pd.DataFrame(index = range(5), columns = ['RMSE', 'MAE']) # Training set\n",
    "\n",
    "\n",
    "for k in range(5):\n",
    "    # Split data set into training set and testing set\n",
    "    traindata = ratings.loc[indices != k,:]\n",
    "    testdata = ratings.loc[indices == k,:]\n",
    "    \n",
    "    # Get mean ratings for training set\n",
    "    user_mean_ratings = get_ratings_per_user(traindata) # Mean rating per user\n",
    "    movie_mean_ratings = get_ratings_per_movie(traindata) # Mean rating per movie\n",
    "    \n",
    "    # Get mean ratings for testing set\n",
    "    test_user_mean = get_ratings_per_user(testdata) # Mean rating per user\n",
    "    test_movie_mean = get_ratings_per_movie(testdata)  # Mean rating per movie\n",
    "    \n",
    "    # Add mean rating per user & mean rating per movie to the training set\n",
    "    ratings_extended = get_ratings_extended(user_mean_ratings, movie_mean_ratings, traindata)\n",
    "    ratings_extended_t = get_ratings_extended(test_user_mean, test_movie_mean, testdata)\n",
    "\n",
    "    # Add extra columns to the test and training set - Used for adding predictions from both LR models\n",
    "    testdata['Predicted_Rating_reg2'] = 999    \n",
    "    traindata['Predicted_Rating_reg2'] = 999\n",
    "    \n",
    "    # Create a linear regression model with intercept using mean rating per user and mean rating per movie\n",
    "    regression_2 = LinearRegression(fit_intercept = True).fit(X = ratings_extended[['usermean', 'itemmean']],\n",
    "                                                               y = traindata['Rating'])\n",
    "   \n",
    "    # Predict ratings using the both linear regression models on the testing set\n",
    "    testdata['Predicted_Rating_reg2'] = regression_2.predict(X = ratings_extended_t[['usermean', 'itemmean']])\n",
    "\n",
    "    # Predict ratings using the both linear regression models on the training set    \n",
    "    traindata['Predicted_Rating_reg2'] = regression_2.predict(X = ratings_extended[['usermean', 'itemmean']])\n",
    "    \n",
    "    # Testing set\n",
    "    # All prediction below 1 is interpreted as 1. Likewise, prediction above 5 is interpreted as 5.\n",
    "    testdata.loc[testdata.Predicted_Rating_reg2 > 5, 'Rating'] = 5 # above 5 with LR with intercept\n",
    "    testdata.loc[testdata.Predicted_Rating_reg2 < 1, 'Rating'] = 1 # below 1 with LR with intercept\n",
    "    \n",
    "    \n",
    "    # Training set\n",
    "    # All prediction below 1 is interpreted as 1. Likewise, prediction above 5 is interpreted as 5.\n",
    "    traindata.loc[traindata.Predicted_Rating_reg2 > 5, 'Rating'] = 5 # above 5 with LR with intercept\n",
    "    traindata.loc[traindata.Predicted_Rating_reg2 < 1, 'Rating'] = 1 # below 1 with LR with intercept\n",
    "    \n",
    "    \n",
    "    # Calculate RMSE and MAE for the testing set on LR model with intercept\n",
    "    mse = (testdata.Rating - testdata.Predicted_Rating_reg2)**2\n",
    "    mae = abs(testdata.Rating- testdata.Predicted_Rating_reg2)\n",
    "    \n",
    "    # Add values to testing error data frame for LR model with intercept\n",
    "    accuracy_per_fold_reg2.loc[k, 'RMSE'] = np.sqrt(sum(mse)/len(mse))\n",
    "    accuracy_per_fold_reg2.loc[k, 'MAE'] = (sum(mae)/len(mae))\n",
    "    \n",
    "\n",
    "    # Calculate RMSE and MAE for the training set on LR model with intercept\n",
    "    mse = (traindata.Rating - traindata.Predicted_Rating_reg2)**2\n",
    "    mae = abs(traindata.Rating- traindata.Predicted_Rating_reg2)\n",
    "    \n",
    "    # Add values to training set error data frame for LR model with intercept    \n",
    "    accuracy_per_fold_reg2.loc[k, 'RMSE'] = np.sqrt(sum(mse)/len(mse))\n",
    "    accuracy_per_fold_reg2.loc[k, 'MAE'] = (sum(mae)/len(mae))\n",
    "\n",
    "print(\"MAE on Testing set for Regression:\\t\", accuracy_per_fold_reg2.loc[:,'MAE'].mean()) #Average the MAEs\n",
    "print(\"RMSE on Testing set for Regression:\\t\", accuracy_per_fold_reg2.loc[:,'RMSE'].mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a29ac",
   "metadata": {},
   "source": [
    "# UV Matrix Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea430be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_sub = ratings\n",
    "\n",
    "\n",
    "np.random.seed(120)\n",
    "indices = np.repeat(range(5), (len(ratings_sub)/5)+1)[0:(len(ratings_sub))]\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "\n",
    "#Initializing lists to store the accuracies of the test set\n",
    "rmse_train = []\n",
    "rmse_test = []\n",
    "mae_train = []\n",
    "mae_test = []\n",
    "\n",
    "\n",
    "\n",
    "for k in range(5): #Cross-validation\n",
    "    \"\"\"Procedure of selecting training set: \n",
    "  - We use all rows, so also the ones of test set, because otherwise the UV matrices aren't \n",
    "    of the correct dimensionality, and therefore predictions wouldn't be possible\n",
    "  - We set all test set elements to 'nan' i.e. blank\n",
    "  - We make a utility matrix\"\"\"\n",
    "    print(k)\n",
    "    train_dat = ratings_sub.copy()\n",
    "    train_dat.loc[indices == k, 'Rating'] = 'nan' #Make ratings of all rows from test set blank elements \n",
    "    M_train = train_dat.pivot(index = 'UserID', columns = 'MovieID', values = 'Rating').to_numpy(dtype=float) #utility matrix\n",
    "    temp_M = np.copy(M_train) # Create copy of M to have a modified version of it for normalization\n",
    "  \n",
    "    # Preprocessing: we normalize the utility matrix M\n",
    "    #Step 1: subtract from each element its row mean\n",
    "    i = 0\n",
    "    for row in temp_M: \n",
    "        temp_M[i] = row - np.nanmean(row) \n",
    "        i += 1\n",
    "\n",
    "    #Step 2: subtract from each element its column mean\n",
    "    i = 0\n",
    "    for col in temp_M.T: \n",
    "        temp_M.T[i] = col - np.nanmean(col)\n",
    "        i += 1\n",
    "\n",
    "     # Initialization\n",
    "    n = temp_M.shape[0] #Amount of users\n",
    "    m = temp_M.shape[1] #Amount of movies\n",
    "\n",
    "    a = np.nanmean(temp_M) # the average nonblank element of M\n",
    "    d = 10 # the lengths of the short sides of U and V, i.e. amount of features chosen\n",
    "\n",
    "    #Initialize U V matrix\n",
    "    U = np.ones((n, d), dtype=float)\n",
    "    V = np.ones((d, m), dtype=float)\n",
    "    \"\"\"Because of the normalization the mean of the M matrix would be 0, so np.sqrt(a/d) -a frequently \n",
    " used initialization strategy that returns for a given entry m_ij the global average - would be 0 as well\"\"\"\n",
    "    U[:] = np.random.normal(0,0.1,U.shape) # starting points for U; add some random noise\n",
    "    V[:] = np.random.normal(0,0.1,(V.shape))#starting points for V; add some random noise \n",
    "    #P = U.dot(V) # P = U * V\n",
    "\n",
    "\n",
    "    \n",
    "  \n",
    "  #Converting all index combinations to tuples such that we don't have a loop within a loop(loop over the \n",
    "  #rows and loop over the columns), but just 1 loop over all the tuples.\n",
    "    inds_U = np.where(U)\n",
    "    inds_V = np.where(V)\n",
    "    rmse_new = 998 # Initializing values for RMSE\n",
    "    rmse_old = 999 # Initializing values for RMSE\n",
    "\n",
    "    # Performing the optimization process:\n",
    "\n",
    "    while(rmse_new > 1e-3 and (rmse_old - rmse_new)>1e-4): # While rmse or improvement is above the threshold (Chosen at random), keep updating\n",
    "        rmse_old = rmse_new\n",
    "\n",
    "        #We iterate over every index combination, i.e. every entry, of the U matrix, and compute\n",
    "        #For that entry the value that would make the derivative of the loss function 0, i.e. the optimal value.\n",
    "        for r, s in zip(*inds_U):\n",
    "            num = np.nansum(V[s,:] *(temp_M[r,:]-(np.matmul(np.delete(U,s, axis = 1)[r],np.delete(V, s, axis =0))))) #numerator\n",
    "            denom = sum(V[s,:][~np.isnan(temp_M[r,:])]**2) #denominator\n",
    "            U[r,s] = num/denom #Split numerator and denominator up to make code more readable\n",
    "\n",
    "        #After having updated the U matrix, we iterate over every index combination, i.e. every entry, of the V matrix, \n",
    "        #and compute for that entry the value that would make the derivative of the loss function 0, i.e. the optimal value.\n",
    "        for r, s in zip(*inds_V):\n",
    "            num = np.nansum(U[:,r] *(temp_M[:,s]- np.matmul(np.delete(U,r, axis = 1),(np.delete(V, r, axis =0)[:,s])))) #numerator\n",
    "            denom = (sum(U[:,r][~np.isnan(temp_M[:,s])]**2)) #denominator\n",
    "            V[r,s] = num/denom #Numerator and denominator split up to make code more readable\n",
    "    \n",
    "        P = U.dot(V) # P = U * V -> current version of UV after 1 optimization training set\n",
    "        rmse_new = np.sqrt(np.nanmean((temp_M-P)**2)) # Keeping track of the RMSE reduction:\n",
    "    \n",
    "        print(rmse_new)\n",
    "\n",
    "      #Reverse the normalization (which was carried out earlier) of the UV-multiplication, such that we are able to \n",
    "      #compare predicted values with the true values in the original (test) data.\n",
    "\n",
    "\n",
    "    for i in range(temp_M.shape[0]): \n",
    "        P[i,:] = P[i,:] + np.nanmean(M_train[i,:]) \n",
    "\n",
    "    for i in range(temp_M.shape[1]): \n",
    "        P[:,i] = P[:,i] + np.nanmean(M_train[:,i])\n",
    "    \n",
    "    P[P < 1] = 1\n",
    "    P[P > 5] = 5\n",
    "    #Accuracy training data:\n",
    "    rmse_train_fold = np.sqrt(np.nanmean((M_train-P)**2))\n",
    "    mae_train_fold = np.nanmean(abs(M_train-P)) \n",
    "    rmse_train.append(rmse_train_fold) #In the end this is a list of length k, for every CV looping 1 result\n",
    "    mae_train.append(mae_train_fold) #In the end this is a list of length k, for every CV looping 1 result\n",
    "    \n",
    "    \"\"\"Procedure of selecting test set: \n",
    "  - We use all rows, so also the ones of training set, because otherwise the utility matrix of the test set doesn't match\n",
    "  the dimensionality of the UV matrices and therefore predictions wouldn't be possible\n",
    "  - We set all training set elements to 'nan' i.e. blank (we only assess accuracy on the test set)\n",
    "  - We make a utility matrix\"\"\"\n",
    "    \n",
    "    test_dat = ratings_sub.copy()\n",
    "    test_dat.loc[indices != k, 'Rating'] = 'nan' #Make ratings of all rows from train set blank elements,\n",
    "    #such that it returns only the non-blank (i.e. test) elements in computing the RMSE\n",
    "    M_test = test_dat.pivot(index = 'UserID', columns = 'MovieID', values = 'Rating').to_numpy(dtype=float)\n",
    "    rmse_test_fold = np.sqrt(np.nanmean((M_test-P)**2)) # Returns RMSE based on test set of the kth fold\n",
    "    mae_test_fold = np.nanmean(abs(M_test-P)) #Returns the MAE of the test set of the kth fold\n",
    "    rmse_test.append(rmse_test_fold) #In the end this is a list of length k, for every CV looping 1 result\n",
    "    mae_test.append(mae_test_fold) #In the end this is a list of length k, for every CV looping 1 result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ff029",
   "metadata": {},
   "source": [
    "# Matrix Factorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on a subset\n",
    "ratings_sub = ratings\n",
    "np.random.seed(120)\n",
    "indices = np.repeat(range(5), (len(ratings_sub)/5)+1)[0:(len(ratings_sub))]\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "all_rmse_train = []\n",
    "all_mae_train = []\n",
    "all_rmse_test = []\n",
    "all_mae_test = []\n",
    "#Procedure according to p.24 of gravity_Tikk article:\n",
    "for k in range(5):\n",
    "    mse_old = 100\n",
    "    mse_new = 99\n",
    "    counter = 0\n",
    "    #Initializing: \n",
    "    train_dat = ratings_sub.copy()\n",
    "    train_dat.loc[indices == k, 'Rating'] = 'nan' #Make ratings of all rows from test set blank elements \n",
    "    M = train_dat.pivot(index = 'UserID', columns = 'MovieID', values = 'Rating').to_numpy(dtype=float)\n",
    "    inds = np.where(~np.isnan(M))\n",
    "\n",
    "    d = 10\n",
    "    n = M.shape[0] #Amount of users\n",
    "    m = M.shape[1] #Amount of movies\n",
    "\n",
    "  \n",
    "    #Initialize U V matrix\n",
    "    U = np.random.normal(0,1, (n,d)) #Random initialization, to be decided on. At least don't use constant vectors\n",
    "    #Because then it will stay constant\n",
    "    V = np.random.normal(0,1, (d,m))\n",
    "    while(counter < 75):\n",
    "        U_new = U.copy() # Creating copies to update U in\n",
    "        V_new = V.copy()\n",
    "\n",
    "        mse_old = mse_new\n",
    "        for i,j in zip(*inds):\n",
    "            err = M[i,j] - np.dot(U_new[i,:], V_new[:,j])\n",
    "            U = U_new.copy()\n",
    "            U_new[i,:] = U_new[i,:] + 0.005*((2*err*V_new[:,j]) - 0.05*U_new[i,:])\n",
    "            V_new[:,j] = V_new[:,j] + 0.005*((2*err*U[i,:]) - 0.05*V_new[:,j]) \n",
    "            \"\"\"Note: for V_new updating, I use the U[i,:] from the previous iteration, such that I update U and V\n",
    "            simultaneously for the gradient of a certain e_i,j\"\"\"\n",
    "        U = U_new.copy() \n",
    "        V = V_new.copy()\n",
    "        mse_new = np.nanmean(err)#MSE\n",
    "        counter +=1\n",
    "        \n",
    "    P = np.dot(U,V)\n",
    "  \n",
    "    #Rounding:\n",
    "    P[P < 1] = 1\n",
    "    P[P > 5] = 5\n",
    "\n",
    "    # Testing on training set:\n",
    "    rmse_train_fold = np.sqrt(np.nanmean((M-P)**2)) # Returns RMSE (when squared value = False)\n",
    "    mae_train_fold = np.nanmean(abs(M-P))\n",
    "    all_rmse_train.append(rmse_train_fold)\n",
    "    all_mae_train.append(mae_train_fold)\n",
    "\n",
    "\n",
    "    #Testing on test set:\n",
    "\n",
    "    test_dat = ratings_sub.copy()\n",
    "    test_dat.loc[indices != k, 'Rating'] = 'nan' #Make ratings of all rows from train set blank elements,\n",
    "    #such that it returns only the non-blank (i.e. test) elements in computing the RMSE\n",
    "    M_test = test_dat.pivot(index = 'UserID', columns = 'MovieID', values = 'Rating').to_numpy(dtype=float)\n",
    "    rmse_test_fold = np.sqrt(np.nanmean((M_test-P)**2)) # Returns RMSE (when squared value = False)\n",
    "    mae_test_fold = np.nanmean(abs(M_test-P))\n",
    "    all_rmse_test.append(rmse_test_fold)\n",
    "    all_mae_test.append(mae_test_fold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
